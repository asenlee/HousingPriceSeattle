---
title: "Project - Report"
author: "Parham Pishrobat (71097927), Asen Lee (97629497), "
output: pdf_document
---

```{r 0-setup, message=FALSE, warning=FALSE, include=FALSE}
# load required libraries, and set up documents global option
knitr::opts_chunk$set(echo = FALSE)
options(knitr.table.format = "simple")
library(dplyr)
library(tidyr)
library(magrittr)
library(rpart)
library(randomForest)
library(glmnet)
library(mgcv)
library(e1071)
library(gbm)
library(caret)
```


```{r 0-load, message=FALSE, warning=FALSE, include=FALSE}
load_data <- function() {
  training   <- read.csv('train.csv')
  testing    <- read.csv('test.csv')
  return(list(training = training, testing = testing))
}
dat   <- load_data()
```



```{r 1-clean, message=FALSE, warning=FALSE, include=FALSE}
# (after preliminary visualization), clean the data by filtering out meaningless 
# predictors, removing missing values, factoring categorical predictors, 
# filtering outliers, filtering or balancing unbalanced classes, and making
# a proper transformations
clean_data <- function(dat) { 
  trainingC <- dat$training %>%
    drop_na() %>%
    filter(price < 1e7 & lot_size_units != "acre") %>%
    mutate(zip   = factor(zip_code),
           lot = lot_size,
           price = sqrt(price)) %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  testingC <- dat$testing %>%
    drop_na() %>%
    filter(price < 1e7 & lot_size_units != "acre") %>%
    mutate(zip   = factor(zip_code, levels = levels(trainingC$zip)),
           lot = lot_size,
           price = sqrt(price)) %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  return(list(training = trainingC, testing = testingC))
}

clean_data2 <- function(dat) { 
  trainingC <- dat$training %>%
    drop_na() %>%
    filter(price < 1e7) %>%
    mutate(zip   = factor(zip_code),
           lot   = if_else(lot_size_units == "acre", lot_size*43560, lot_size),
           price = price/1000) %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  testingC <- dat$testing %>%
    drop_na() %>%
    filter(price < 1e7) %>%
    mutate(zip   = factor(zip_code, levels = levels(trainingC$zip)),
           lot   = if_else(lot_size_units == "acre", lot_size*43560, lot_size),
           price = price/1000) %>%
    drop_na() %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  return(list(training = trainingC, testing = testingC))
}


dat   <- clean_data(dat)
training <- dat$training
testing  <- dat$testing


```



```{r 2-summarize, echo=FALSE, message=FALSE, warning=FALSE}
# produce many summary statistics and simple plots (some of the results such as correlations are saved in obj)
summarize_data <- function(training, output = T) {
  vars  <- colnames(training)
  n     <- ncol(training)
  corr  <- double(n-1)
  print(cor(training[,-1]))
  for (i in 2:(n-1)) {
    corr[i] <- round(cor(training$price, training[, i]), 2)
    if (output) {
      plot(training[, i], training$price, ylab="price", xlab=vars[i])
      plot(training$zip,   training[, i], xlab="zipcode", ylab=vars[i])
    }
  }
  corr[1] <- 1
  return(list(corr = corr, vars = vars))
}
res <- summarize_data(training, output = T)
```





```{r 3-plot model, message=FALSE, warning=FALSE, include=FALSE}
plot_model <- function(training, fitted, testing, preds) {
  varNames <- colnames(training)
  par(mfrow = c(1, 2))
  for (i in 4:5) {
    plot(training[, i],  fitted - training$price,             # residuals vs predictors plots
         xlab = varNames[i], ylab = "Residuals",
         main = paste("Residual vs", varNames[i]),
         ylim = c(-1000, 1000), pch = 16, cex = 0.5)
  }
  plot(fitted, training$price, 
       xlab = "Fitted Values", ylab = "Observed",
       main = "Observed vs Fitted Values",
       xlim = c(0, 2000),  ylim = c(0, 2000), pch = 16, cex = 0.5)
  lines(seq(1,2000), seq(1,2000), type = "l", col = "red")
  plot(preds, testing$price, 
       xlab = "Predicted", ylab = "Actual",
       main = "Predictions vs Actual Values",
       xlim = c(0, 2000),  ylim = c(0, 2000), pch = 16, cex = 0.5)
  lines(seq(1,2000), seq(1,2000), type = "l", col = "red")
  plot(training$price, training$price - fitted, 
       xlab = "Predicted", ylab = "Actual",
       main = "Predictions vs Actual Values",
       ylim = c(-1000, 1000), pch = 16, cex = 0.5)
  x <- rnorm(100)
  qqnorm(x, main = "QQ Plot of Random Normal Data", col = "blue")
  qqline(x, col = "red")
  par(mfrow = c(1, 2))
  hist(training$price, main = "training Data Distribution")
  hist(testing$price, main = "testing Data Distribution")

}
```



```{r 4.1-model ols, echo=FALSE, message=FALSE, warning=FALSE}
ols <- function(training, testing) {
  mod   <- lm(price~., data = training)
  preds80 <- predict(mod, newdata = testing, interval="predict", level=0.8)
  preds50 <- predict(mod, newdata = testing, interval="predict", level=0.5)
  plot_model(training, mod$fitted.values, testing, preds50[, 1])
  return(list(model = mod, preds50 = preds50, preds80 = preds80))
}
olsMod <- ols(training, testing)
```




```{r 4.2-model wls, echo=FALSE, message=FALSE, warning=FALSE}
wls <- function(training, testing) {
  priceW <- sort(training$price)
  pRange <- diff(range(priceW)) 
  len    <- length(priceW)
  w      <- double(len)
  r      <- (training$price - min(priceW))/pRange
  for (i in 1:len) {
    w[i] <- 1/sd(priceW[max((floor((r[i]-0.05)*len)), 1):min(floor((r[i]+0.05)*len), len)])
  }
  
  
  priceWT <- sort(testing$price)
  pRangeT <- diff(range(priceWT)) 
  lenT    <- length(priceWT)
  wT      <- double(lenT)
  rT      <- (testing$price - min(priceWT))/pRangeT
  for (i in 1:lenT) {
    wT[i] <- 1/sd(priceWT[max((floor((rT[i]-0.05)*lenT)), 1):min(floor((rT[i]+0.05)*lenT), lenT)])
  }

  mod   <- lm(price~., data = training, weights = w)
  preds80 <- predict(mod, newdata = testing, interval="predict", level=0.8, weights = wT)
  preds50 <- predict(mod, newdata = testing, interval="predict", level=0.5, weights = wT)
  plot_model(training, mod$fitted.values, testing, preds50[, 1])
  return(list(model = mod, preds50 = preds50, preds80 = preds80))
}
wlsMod <- wls(training, testing)
```


```{r 4.3-model qrf, echo=FALSE, message=FALSE, warning=FALSE}
qrf <- function(training, testing) {
  Y <- training$price
  X <- training %>% select(-price)
  mod <- quantregForest(X, Y)
  
  # 50%, 80% prediction intervals
  newX <- testing %>% select(-price)
  preds <- predict(mod, what=c(.1, .25, .5, .75, .9), newdata=newX)
  plot_model(training, mod$predicted, testing, preds[, 3])
  preds50 <<- preds[c(3, 2, 4)]
  return(list(model = mod, preds50 = preds[, c(3, 2, 4)], preds80 = preds[, c(3, 1, 5)]))
}

qrfMod <- qrf(training, testing)
```


```{r 4.4-model grb, echo=FALSE, message=FALSE, warning=FALSE}
grb <- function(training, testing) {
  mod     <- gbm(price ~ ., data = training, n.trees = 100, shrinkage = 0.1, 
                 interaction.depth = 3, distribution = "gaussian",)
  preds80 <- predict(mod, newdata = testing, type = "response", se.fit = TRUE, interval="prediction", level=0.8)
  preds50 <- predict(mod, newdata = testing, type = "response", se.fit = TRUE, interval="prediction", level=0.5)
  plot_model(training, mod$fit, testing, preds50) 
  return(list(model = mod, preds50 = preds50, preds80 = preds80))
}
grbMod <- grb(training, testing)
```






```{r 5- prediction interval, echo=FALSE, message=FALSE, warning=FALSE}
#' Interval score function for prediction intervals, smaller value is better
#' @description
#' Interval score for prediction intervals
#'
#' @param predobj has 3 (or more) columns: pointprediction, predLB, predUB
#' @param actual corresponding vector of actual values
# (in holdout set, for example)
#' @param level level for prediction interval, e.g., 0.5 or 0.8
#' @return list with
#' summary consisting of level, average length, interval score, coverage rate
#' and
#' imiss with cases where prediction intervals don't contain actual values
#'
intervalScore <- function(predObj, actual, level) { 
  n <- nrow(predObj)
  alpha     <- 1- level
  ilow      <- (actual<predObj[,2]) # overestimation
  ihigh     <- (actual>predObj[,3]) # underestimation
  sumlength <- sum(predObj[,3]-predObj[,2]) # sum of lengths of prediction intervals
  sumlow    <- sum(predObj[ilow,2]-actual[ilow])*2/alpha
  sumhigh   <- sum(actual[ihigh]-predObj[ihigh,3])*2/alpha
  avglength <- sumlength/n
  IS        <- (sumlength+sumlow+sumhigh)/n # average length + average under/over penalties
  cover     <- mean(actual>= predObj[,2] & actual<=predObj[,3])
  summ      <- c(level,avglength,IS,cover)
  # summary with level, average length, interval score, coverage rate
  imiss     <- which(ilow | ihigh)
  list(summary=summ, imiss=imiss)
}
```


```{r 5.2- prediction interval, echo=FALSE, message=FALSE, warning=FALSE}
cat("----------OLS MODEL-------------------------------------\n")
IS50ols <- intervalScore(olsMod$preds50, testing$price, 0.5)
IS80ols <- intervalScore(olsMod$preds80, testing$price, 0.8)
outols  <- rbind(IS50ols$summary, IS80ols$summary)
colnames(outols) = c( "level", "avgleng", "IS", "cover")
print(outols)

cat("----------WLS MODEL-------------------------------------\n")
IS50wls <- intervalScore(wlsMod$preds50, testing$price, 0.5)
IS80wls <- intervalScore(wlsMod$preds80, testing$price, 0.8)
outwls  <- rbind(IS50wls$summary, IS80wls$summary)
colnames(outwls) = c( "level", "avgleng", "IS", "cover")
print(outwls)

cat("----------QRF MODEL-------------------------------------\n")
IS50qrf <- intervalScore(qrfMod$preds50, testing$price, 0.5)
IS80qrf <- intervalScore(qrfMod$preds80, testing$price, 0.8)
outqrf  <- rbind(IS50qrf$summary, IS80qrf$summary)
colnames(outqrf) = c( "level", "avgleng", "IS", "cover")
print(outqrf)



```



```{r eln}
eln <- function(training, testing) {
  mod <- gbm(price ~ ., data = training, n.trees = 1000, shrinkage = 0.5, interaction.depth = 4,  verbose = TRUE)

  preds <- predict(mod, newdata = testing)
  return(list(model = mod))#, preds = preds))
}
grbMod <- grb(training, testing)
```



```{r 4-predict, message=FALSE, warning=FALSE, include=FALSE}
# given fitted models and testing dataset, compute prediction
#predict_price <- function(obj) { 
#
# return(obj)
#}
```



```{r 5-validate, message=FALSE, warning=FALSE, include=FALSE}
# using all models and holdout predictions, compute diagnostic measures 
#validate_model <- function(obj) { 

# return(obj)
#}
```



```{r 6-select, message=FALSE, warning=FALSE, include=FALSE}
# based on the diagnostics computed in the validation stage, select the best performer
#select_model <- function(obj) { 

# return(obj)
#}
```



```{r main, message=FALSE, warning=FALSE, include=FALSE}
# main <- function(training, testing) {
#   
#   analysis   <- training %>%
#     clean_data() %>%                                          # 1. clean
#     summarize_data(output = F) %>%                              # 2. summarize 
#     fit_model() %>%                                             # 3. model
#     predict_price(testing) %>%                                     # 4. predict
#     validate_model() %>%                                        # 5. validate
#     select_model() %>%                                          # 6. select
#   
#   return(list(trainingR    = analysis$training,
#               trainingT    = analysis$trainingT,
#               testingR     = analysis$testing,
#               testingT     = analysis$testingT,
#               models    = analysis$models,
#               preds50   = analysis$preds50,
#               preds80   = analysis$preds80,
#               best      = analysis$best))
# }
```





##### Data:


##### Precleaning:


 

##### Methods:




##### Results:


```{r run, echo=FALSE, message=FALSE, warning=FALSE}
# testing    <- read.csv('test.csv')   
# training   <- read.csv('train.csv') 
# output  <- main(training, testing)
```


```{r results, echo=FALSE, message=FALSE, warning=FALSE}

```


##### Interpretation:



```{r plots, echo=FALSE, message=FALSE, warning=FALSE}

```




 