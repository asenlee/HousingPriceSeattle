---
title: "Project - Report"
author: "Parham Pishrobat (71097927), Asen Lee (97629497), "
output: pdf_document
---

```{r 0-setup, message=FALSE, warning=FALSE, include=FALSE}
# load required libraries, and set up documents global option
knitr::opts_chunk$set(echo = FALSE)
options(knitr.table.format = "simple")
library(dplyr)
library(tidyr)
library(magrittr)
library(rpart)
library(randomForest)
library(glmnet)
library(mgcv)
library(e1071)
library(gbm)
library(caret)
```


```{r 0-load, message=FALSE, warning=FALSE, include=FALSE}
load_data <- function() {
  training   <- read.csv('train.csv')
  testing    <- read.csv('test.csv')
  return(list(training = training, testing = testing))
}
dat   <- load_data()
```



```{r 1-clean, message=FALSE, warning=FALSE, include=FALSE}
# (after preliminary visualization), clean the data by filtering out meaningless 
# predictors, removing missing values, factoring categorical predictors, 
# filtering outliers, filtering or balancing unbalanced classes, and making
# a proper transformations
clean_data <- function(dat) { 
  trainingC <- dat$training %>%
    drop_na() %>%
    filter(price < 1e7 & lot_size_units != "acre") %>%
    mutate(zip   = factor(zip_code),
           lot = lot_size,
           price = sqrt(price)) %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  testingC <- dat$testing %>%
    drop_na() %>%
    filter(price < 1e7 & lot_size_units != "acre") %>%
    mutate(zip   = factor(zip_code, levels = levels(trainingC$zip)),
           lot = lot_size,
           price = sqrt(price)) %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  return(list(training = trainingC, testing = testingC))
}
dat   <- clean_data(dat)
training <- dat$training
testing  <- dat$testing
```



```{r 2-summarize, echo=FALSE, message=FALSE, warning=FALSE}
# produce many summary statistics and simple plots (some of the results such as correlations are saved in obj)
summarize_data <- function(training, output = T) {
  vars  <- colnames(training)
  n     <- ncol(training)
  corr  <- double(n-1)
  print(cor(training[,-1]))
  for (i in 2:(n-1)) {
    corr[i] <- round(cor(training$price, training[, i]), 2)
    if (output) {
      plot(training[, i], training$price, ylab="price", xlab=vars[i])
      plot(training$zip,   training[, i], xlab="zipcode", ylab=vars[i])
    }
  }
  corr[1] <- 1
  return(list(corr = corr, vars = vars))
}
res <- summarize_data(training, output = T)
```





```{r 3-plot model, message=FALSE, warning=FALSE, include=FALSE}
plot_model <- function(training, fitted, testing, preds) {
  varNames <- colnames(training)
  par(mfrow = c(1, 2))
  for (i in 4:5) {
    plot(training[, i],  fitted - training$price,             # residuals vs predictors plots
         xlab = varNames[i], ylab = "Residuals",
         main = paste("Residual vs", varNames[i]),
         ylim = c(-1000, 1000), pch = 16, cex = 0.5)
  }
  plot(fitted, training$price, 
       xlab = "Fitted Values", ylab = "Observed",
       main = "Observed vs Fitted Values",
       xlim = c(0, 2000),  ylim = c(0, 2000), pch = 16, cex = 0.5)
  lines(seq(1,2000), seq(1,2000), type = "l", col = "red")
  plot(preds, testing$price, 
       xlab = "Predicted", ylab = "Actual",
       main = "Predictions vs Actual Values",
       xlim = c(0, 2000),  ylim = c(0, 2000), pch = 16, cex = 0.5)
  lines(seq(1,2000), seq(1,2000), type = "l", col = "red")
  plot(training$price, training$price - fitted, 
       xlab = "Predicted", ylab = "Actual",
       main = "Predictions vs Actual Values",
       ylim = c(-1000, 1000), pch = 16, cex = 0.5)
  x <- rnorm(100)
  qqnorm(x, main = "QQ Plot of Random Normal Data", col = "blue")
  qqline(x, col = "red")
  par(mfrow = c(1, 2))
  hist(training$price, main = "training Data Distribution")
  hist(testing$price, main = "testing Data Distribution")

}
```



```{r 4.1-model ols, echo=FALSE, message=FALSE, warning=FALSE}
ols <- function(training, testing) {
  mod   <- lm(price~., data = training)
  preds80 <- predict(mod, newdata = testing, interval="predict", level=0.8)
  preds50 <- predict(mod, newdata = testing, interval="predict", level=0.5)
  plot_model(training, mod$fitted.values, testing, preds50[, 1])
  return(list(model = mod, preds50 = preds50, preds80 = preds80))
}
olsMod <- ols(training, testing)
```




```{r 4.2-model wls, echo=FALSE, message=FALSE, warning=FALSE}
wls <- function(training, testing) {
  priceW <- sort(training$price)
  pRange <- diff(range(priceW)) 
  len    <- length(priceW)
  w      <- double(len)
  r      <- (training$price - min(priceW))/pRange
  for (i in 1:len) {
    w[i] <- 1/sd(priceW[max((floor((r[i]-0.1)*len)), 1):min(floor((r[i]+0.1)*len), len)])
  }

  mod   <- lm(price~., data = training, weights = w)
  preds80 <- predict(mod, newdata = testing, interval="predict", level=0.8)
  preds50 <- predict(mod, newdata = testing, interval="predict", level=0.5)
  plot_model(training, mod$fitted.values, testing, preds50[, 1])
  return(list(model = mod, preds50 = preds50, preds80 = preds80))
}
wlsMod <- wls(training, testing)
```

Heteroscedasiticity removed





```{r wls}
grb <- function(training, testing) {
  mod     <- gbm(price ~ ., data = training, n.trees = 1000, shrinkage = 0.1, interaction.depth = 3)
  preds80 <- predict(mod, newdata = testing, type = "response", se.fit = TRUE, interval="prediction", level=0.8)
  preds50 <- predict(mod, newdata = testing, type = "response", se.fit = TRUE, interval="prediction", level=0.5)
  plot_model(training, mod$fit, testing, preds50) 
  return(list(model = mod, preds50 = preds50, preds80 = preds80))
}
grbMod <- grb(training, testing)
```


```{r wls}
eln <- function(training, testing) {
  mod <- gbm(price ~ ., data = training, n.trees = 1000, shrinkage = 0.5, interaction.depth = 4,  verbose = TRUE)

  preds <- predict(mod, newdata = testing)
  return(list(model = mod))#, preds = preds))
}
grbMod <- grb(training, testing)
```



```{r 4-predict, message=FALSE, warning=FALSE, include=FALSE}
# given fitted models and testing dataset, compute prediction
#predict_price <- function(obj) { 
#
# return(obj)
#}
```



```{r 5-validate, message=FALSE, warning=FALSE, include=FALSE}
# using all models and holdout predictions, compute diagnostic measures 
#validate_model <- function(obj) { 

# return(obj)
#}
```



```{r 6-select, message=FALSE, warning=FALSE, include=FALSE}
# based on the diagnostics computed in the validation stage, select the best performer
#select_model <- function(obj) { 

# return(obj)
#}
```



```{r main, message=FALSE, warning=FALSE, include=FALSE}
# main <- function(training, testing) {
#   
#   analysis   <- training %>%
#     clean_data() %>%                                          # 1. clean
#     summarize_data(output = F) %>%                              # 2. summarize 
#     fit_model() %>%                                             # 3. model
#     predict_price(testing) %>%                                     # 4. predict
#     validate_model() %>%                                        # 5. validate
#     select_model() %>%                                          # 6. select
#   
#   return(list(trainingR    = analysis$training,
#               trainingT    = analysis$trainingT,
#               testingR     = analysis$testing,
#               testingT     = analysis$testingT,
#               models    = analysis$models,
#               preds50   = analysis$preds50,
#               preds80   = analysis$preds80,
#               best      = analysis$best))
# }
```





##### Data:


##### Precleaning:


 

##### Methods:




##### Results:


```{r run, echo=FALSE, message=FALSE, warning=FALSE}
# testing    <- read.csv('test.csv')   
# training   <- read.csv('train.csv') 
# output  <- main(training, testing)
```


```{r results, echo=FALSE, message=FALSE, warning=FALSE}

```


##### Interpretation:



```{r plots, echo=FALSE, message=FALSE, warning=FALSE}

```




 