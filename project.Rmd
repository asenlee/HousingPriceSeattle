---
title: "Project - Report"
author: "Parham Pishrobat (71097927), Asen Lee (97629497), "
output: pdf_document
---

```{r 0-setup, message=FALSE, warning=FALSE, include=FALSE}
# load required libraries, and set up documents global option
knitr::opts_chunk$set(echo = FALSE)
options(knitr.table.format = "simple")
library(dplyr)
library(tidyr)
library(magrittr)
library(rpart)
library(randomForest)
library(glmnet)
library(mgcv)
library(e1071)
library(gbm)
library(caret)
```



```{r 1-clean, message=FALSE, warning=FALSE, include=FALSE}
# (after preliminary visualization), clean the data by filtering out meaningless 
# predictors, removing missing values, factoring categorical predictors, 
# filtering outliers, filtering or balancing unbalanced classes, and making
# a proper transformations
clean_data <- function(train, test) { 
  trainC <- train %>%
    drop_na() %>%
    filter(price < 1e7) %>%
    mutate(zip   = factor(zip_code),
           lot   = if_else(lot_size_units == "acre", lot_size*43560, lot_size),
           price = price/1000) %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  testC <- test %>%
    drop_na() %>%
    filter(price < 1e7) %>%
    mutate(zip   = factor(zip_code, levels = levels(trainC$zip)),
           lot   = if_else(lot_size_units == "acre", lot_size*43560, lot_size),
           price = price/1000) %>%
    drop_na() %>%
    filter( lot < 1e5) %>%
    select(zip, beds, baths, size, lot, price)
  return(list(train = trainC, test = testC))
}
```



```{r 2-summarize, message=FALSE, warning=FALSE, include=FALSE}
# produce many summary statistics and simple plots (some of the results such as correlations are saved in obj)
summarize_data <- function(obj, output = T) { 
  train <- obj$train
  vars  <- colnames(train)
  obj$vars <- vars
  n     <- length(train)
  corr  <- double(n-1)
  print(cor(train[,-1]))
  for (i in 2:(n-1)) {
    corr[i] <- round(cor(train$price, train[, i]), 2)
    if (output) {
      plot(train$price, train[, i], xlab="price", ylab=vars[i])
      plot(train$zip,   train[, i], xlab="price", ylab=vars[i])
    }
  }
  corr[c(1,6)] <- 1
  obj$corr     <- corr
  return(obj)
}
```



```{r dev}
dat   <- clean_data(read.csv('train.csv'), read.csv('test.csv'))
train <- dat$train
test  <- dat$test
```


```{r}
plot_model <- function(train, fitted, test, preds) {
  varNames <- colnames(train)
  par(mfrow = c(1, 2))
  for (i in 4:5) {
    plot(train[, i],  fitted - train$price,             # residuals vs predictors plots
         xlab = varNames[i], ylab = "Residuals",
         main = paste("Residual vs", varNames[i]),
         ylim = c(-2000, 2000), pch = 16, cex = 0.5)
  }
  plot(fitted, train$price, 
       xlab = "Fitted Values", ylab = "Observed",
       main = "Observed vs Fitted Values",
       xlim = c(0, 3000),  ylim = c(0, 3000), pch = 16, cex = 0.5)
  lines(seq(1,4000), seq(1,4000), type = "l", col = "red")
  plot(preds, test$price, 
       xlab = "Predicted", ylab = "Actual",
       main = "Predictions vs Actual Values",
       xlim = c(0, 4000),  ylim = c(0, 4000), pch = 16, cex = 0.5)
  lines(seq(1,4000), seq(1,4000), type = "l", col = "red")
  x <- rnorm(100)
  qqnorm(x, main = "QQ Plot of Random Normal Data", col = "blue")
  qqline(x, col = "red")
  par(mfrow = c(1, 2))
  hist(train$price, main = "Train Data Distribution")
  hist(test$price, main == "Test Data Distribution")

}
```

```{r ols}
ols <- function(train, test) {
  mod   <- lm(price~., data = train)
  preds <- predict(mod, newdata = test)
  plot_model(train, mod$fitted.values, test, preds)
  return(list(model = mod, preds = preds))
}
olsMod <- ols(train, test)
```
Heteroscedasiticity apparent

```{r wls}
wls <- function(train, test) {
  priceW <- sort(train$price)
  pRange <- diff(range(priceW)) 
  len    <- length(priceW)
  w     <<- double(len)
  r     <<- (train$price - min(priceW))/pRange
  for (i in 1:len) {
    w[i] <<- 1/sd(priceW[max((floor((r[i]-0.1)*len)), 1):min(floor((r[i]+0.1)*len), len)])
  }

  mod   <- lm(price~., data = train, weights = w)
  preds <- predict(mod, newdata = test)
  plot_model(train, mod$fitted.values, test, preds)
  return(list(model = mod, preds = preds))
}
wlsMod <- wls(train, test)
```

Heteroscedasiticity removed





```{r wls}
grb <- function(train, test) {
  mod     <- gbm(price ~ ., data = train, n.trees = 1000, shrinkage = 0.1, interaction.depth = 3,  verbose = TRUE)
  preds   <- predict(mod, newdata = test)
  plot_model(train, mod$fit, test, preds) 
  return(list(model = mod, preds = preds))
}
grbMod <- grb(train, test)
```


```{r wls}
eln <- function(train, test) {
  mod <- gbm(price ~ ., data = train, n.trees = 1000, shrinkage = 0.5, interaction.depth = 4,  verbose = TRUE)

  preds <- predict(mod, newdata = test)
  plot(mod$fit, train$price - mod$fit, ylim = c(-3000, 3000), pch = 16)
  plot(preds, test$price - preds, xlim = c(0, 3000),  ylim = c(-4000, 4000), pch = 16)
  return(list(model = mod))#, preds = preds))
}
grbMod <- grb(train, test)
```



```{r 4-predict, message=FALSE, warning=FALSE, include=FALSE}
# given fitted models and test dataset, compute prediction
#predict_price <- function(obj) { 
#
# return(obj)
#}
```



```{r 5-validate, message=FALSE, warning=FALSE, include=FALSE}
# using all models and holdout predictions, compute diagnostic measures 
#validate_model <- function(obj) { 

# return(obj)
#}
```



```{r 6-select, message=FALSE, warning=FALSE, include=FALSE}
# based on the diagnostics computed in the validation stage, select the best performer
#select_model <- function(obj) { 

# return(obj)
#}
```



```{r main, message=FALSE, warning=FALSE, include=FALSE}
# main <- function(train, test) {
#   
#   analysis   <- train %>%
#     clean_data() %>%                                          # 1. clean
#     summarize_data(output = F) %>%                              # 2. summarize 
#     fit_model() %>%                                             # 3. model
#     predict_price(test) %>%                                     # 4. predict
#     validate_model() %>%                                        # 5. validate
#     select_model() %>%                                          # 6. select
#   
#   return(list(trainR    = analysis$train,
#               trainT    = analysis$trainT,
#               testR     = analysis$test,
#               testT     = analysis$testT,
#               models    = analysis$models,
#               preds50   = analysis$preds50,
#               preds80   = analysis$preds80,
#               best      = analysis$best))
# }
```





##### Data:


##### Precleaning:


 

##### Methods:




##### Results:


```{r run, echo=FALSE, message=FALSE, warning=FALSE}
# test    <- read.csv('test.csv')   
# train   <- read.csv('train.csv') 
# output  <- main(train, test)
```


```{r results, echo=FALSE, message=FALSE, warning=FALSE}

```


##### Interpretation:



```{r plots, echo=FALSE, message=FALSE, warning=FALSE}

```




 